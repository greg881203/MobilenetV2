{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3539444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from    tensorflow.keras import layers, models, Sequential, backend\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, ZeroPadding2D, AveragePooling2D, DepthwiseConv2D, Reshape\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "# 保證為8的倍數\n",
    "def make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v+divisor/2)//divisor*divisor) #//向下取整，除\n",
    "    if new_v<0.9*v:\n",
    "        new_v +=divisor\n",
    "    return new_v\n",
    "\n",
    "def pad_size(inputs, kernel_size):\n",
    "\n",
    "    input_size = inputs.shape[1:3]\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1,1)\n",
    "\n",
    "    else:\n",
    "        adjust = (1- input_size[0]%2, 1-input_size[1]%2)\n",
    "    \n",
    "    correct = (kernel_size[0]//2, kernel_size[1]//2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]))\n",
    "\n",
    "def conv_block (x, nb_filter, kernel=(1,1), stride=(1,1), name=None):\n",
    "\n",
    "    x = Conv2D(nb_filter, kernel, strides=stride, padding='same', use_bias=False, name=name+'_expand')(x)\n",
    "    x = BatchNormalization(axis=3, name=name+'_expand_BN')(x)\n",
    "    x = Activation(relu6, name=name+'_expand_relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def depthwise_res_block(x, nb_filter, kernel, stride, t, alpha, resdiual=False, name=None):\n",
    "\n",
    "    input_tensor=x\n",
    "    exp_channels= x.shape[-1]*t  #扩展维度\n",
    "    alpha_channels = int(nb_filter*alpha)     #压缩维度\n",
    "\n",
    "    x = conv_block(x, exp_channels, (1,1), (1,1), name=name)\n",
    "\n",
    "    if stride[0]==2:\n",
    "        x = ZeroPadding2D(padding=pad_size(x, 3), name=name+'_pad')(x)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel, padding='same' if stride[0]==1 else 'valid', strides=stride, depth_multiplier=1, use_bias=False, name=name+'_depthwise')(x)\n",
    "\n",
    "    x = BatchNormalization(axis=3, name=name+'_depthwise_BN')(x)\n",
    "    x = Activation(relu6, name=name+'_depthwise_relu')(x)\n",
    "\n",
    "    x = Conv2D(alpha_channels, (1,1), padding='same', use_bias=False, strides=(1,1), name=name+'_project')(x)\n",
    "    x = BatchNormalization(axis=3, name=name+'_project_BN')(x)\n",
    "\n",
    "    if resdiual:\n",
    "        x = layers.add([x, input_tensor], name=name+'_add')\n",
    "\n",
    "    return x\n",
    "\n",
    "def MovblieNetV2 (alpha=1., dropout=0):\n",
    "\n",
    "    img_input = Input(shape=(540, 960, 3))\n",
    "\n",
    "    first_filter = make_divisible(32*alpha, 8)\n",
    "    \n",
    "    x = ZeroPadding2D(padding=pad_size(img_input, 3), name='Conv1_pad')(img_input)\n",
    "    x = Conv2D(first_filter, (3,3), strides=(2,2), padding='valid', use_bias=False, name='Conv1')(x)\n",
    "    x = BatchNormalization(axis=3, name='bn_Conv1')(x)\n",
    "    x = Activation(relu6, name='Conv1_relu')(x)\n",
    "\n",
    "    x = DepthwiseConv2D((3,3), padding='same', strides=(1,1), depth_multiplier=1, use_bias=False, name='expanded_conv_depthwise')(x)\n",
    "    x = BatchNormalization(axis=3, name='expanded_conv_depthwise_BN')(x)\n",
    "    x = Activation(relu6, name='expanded_conv_depthwise_relu')(x)\n",
    "\n",
    "    x = Conv2D(16, (1,1), padding='same', use_bias=False, strides=(1,1), name='expanded_conv_project')(x)\n",
    "    x = BatchNormalization(axis=3, name='expanded_conv_project_BN')(x)\n",
    "\n",
    "    x = depthwise_res_block(x, 24, (3,3), (2,2), 6, alpha, resdiual=False, name='block_1') \n",
    "\n",
    "    x = depthwise_res_block(x, 24, (3,3), (1,1), 6, alpha, resdiual=True, name='block_2') \n",
    "\n",
    "    x = depthwise_res_block(x, 32, (3,3), (2,2), 6, alpha, resdiual=False, name='block_3')\n",
    "\n",
    "    x = depthwise_res_block(x, 32, (3,3), (1,1), 6, alpha, resdiual=True, name='block_4')\n",
    "\n",
    "    x = depthwise_res_block(x, 32, (3,3), (1,1), 6, alpha, resdiual=True, name='block_5')\n",
    "\n",
    "    x = depthwise_res_block(x, 64, (3,3), (1,1), 6, alpha, resdiual=False, name='block_6')\n",
    "    \n",
    "    x = depthwise_res_block(x, 64, (3,3), (1,1), 6, alpha, resdiual=True, name='block_7')\n",
    "\n",
    "    x = depthwise_res_block(x, 64, (3,3), (1,1), 6, alpha, resdiual=True, name='block_8')\n",
    "\n",
    "    x = depthwise_res_block(x, 64, (3,3), (1,1), 6, alpha, resdiual=True, name='block_9')\n",
    "\n",
    "    x = depthwise_res_block(x, 96, (3,3), (1,1), 6, alpha, resdiual=False, name='block_10')\n",
    "\n",
    "    x = depthwise_res_block(x, 96, (3,3), (1,1), 6, alpha, resdiual=True, name='block_11')\n",
    "\n",
    "    x = depthwise_res_block(x, 96, (3,3), (1,1), 6, alpha, resdiual=True, name='block_12')\n",
    "\n",
    "    model = models.Model(img_input, x, name='MobileNetV2')\n",
    "#     print(model.summary())\n",
    "    return model\n",
    "\n",
    "# x = MovblieNetV2()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21e77e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CSRnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 540, 960, 3)]     0         \n",
      "_________________________________________________________________\n",
      "MobileNetV2 (Functional)     (None, 68, 120, 96)       558656    \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 68, 120, 96)       864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 68, 120, 96)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 68, 120, 192)      1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 68, 120, 192)      768       \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 68, 120, 192)      1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 68, 120, 192)      768       \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "density_map (Conv2D)         (None, 68, 120, 1)        193       \n",
      "=================================================================\n",
      "Total params: 570,849\n",
      "Trainable params: 553,761\n",
      "Non-trainable params: 17,088\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 假設你已經有 img_input 作為輸入\n",
    "img_input = Input(shape=(540, 960, 3))\n",
    "# 使用MobileNetV2\n",
    "mobilenetv2 = MovblieNetV2()(img_input) \n",
    "x = Conv2D(filters=96, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2,groups=96,activation='relu',use_bias=False)(mobilenetv2)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=96,activation='relu',use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu',use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "# 最後輸出density map\n",
    "density_map = Conv2D(filters=1, kernel_size=1, name='density_map')(x)\n",
    "# 建立模型\n",
    "model = Model(img_input, density_map,name = 'CSRnet')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd65baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  tensorflow as tf\n",
    "# from    tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "# from    tensorflow.keras import layers, models, Sequential, backend,Model\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.layers import Concatenate, Lambda, Input, ZeroPadding2D, AveragePooling2D, DepthwiseConv2D, Reshape,Add\n",
    "\n",
    "\n",
    "# def _make_divisible(v, divisor, min_value=None):\n",
    "#     if min_value is None:\n",
    "#         min_value = divisor\n",
    "#     new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "#     # Make sure that round down does not go down by more than 10%.\n",
    "#     if new_v < 0.9 * v:\n",
    "#         new_v += divisor\n",
    "#     return new_v\n",
    "\n",
    "\n",
    "# def relu6(x):\n",
    "#     \"\"\"Relu 6\n",
    "#     \"\"\"\n",
    "#     return K.relu(x, max_value=6.0)\n",
    "\n",
    "\n",
    "# def _conv_block(inputs, filters, kernel, strides):\n",
    "#     \"\"\"Convolution Block\n",
    "#     This function defines a 2D convolution operation with BN and relu6.\n",
    "\n",
    "#     # Arguments\n",
    "#         inputs: Tensor, input tensor of conv layer.\n",
    "#         filters: Integer, the dimensionality of the output space.\n",
    "#         kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "#             width and height of the 2D convolution window.\n",
    "#         strides: An integer or tuple/list of 2 integers,\n",
    "#             specifying the strides of the convolution along the width and height.\n",
    "#             Can be a single integer to specify the same value for\n",
    "#             all spatial dimensions.\n",
    "\n",
    "#     # Returns\n",
    "#         Output tensor.\n",
    "#     \"\"\"\n",
    "\n",
    "#     channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "#     x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "#     x = BatchNormalization(axis=channel_axis)(x)\n",
    "#     return Activation(relu6)(x)\n",
    "\n",
    "\n",
    "# def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "#     \"\"\"Bottleneck\n",
    "#     This function defines a basic bottleneck structure.\n",
    "\n",
    "#     # Arguments\n",
    "#         inputs: Tensor, input tensor of conv layer.\n",
    "#         filters: Integer, the dimensionality of the output space.\n",
    "#         kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "#             width and height of the 2D convolution window.\n",
    "#         t: Integer, expansion factor.\n",
    "#             t is always applied to the input size.\n",
    "#         s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "#             of the convolution along the width and height.Can be a single\n",
    "#             integer to specify the same value for all spatial dimensions.\n",
    "#         alpha: Integer, width multiplier.\n",
    "#         r: Boolean, Whether to use the residuals.\n",
    "\n",
    "#     # Returns\n",
    "#         Output tensor.\n",
    "#     \"\"\"\n",
    "\n",
    "#     channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "#     # Depth\n",
    "#     tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "#     # Width\n",
    "#     cchannel = int(filters * alpha)\n",
    "\n",
    "#     x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "\n",
    "#     x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "#     x = BatchNormalization(axis=channel_axis)(x)\n",
    "#     x = Activation(relu6)(x)\n",
    "\n",
    "#     x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "#     x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "#     if r:\n",
    "#         x = Add()([x, inputs])\n",
    "\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "#     \"\"\"Inverted Residual Block\n",
    "#     This function defines a sequence of 1 or more identical layers.\n",
    "\n",
    "#     # Arguments\n",
    "#         inputs: Tensor, input tensor of conv layer.\n",
    "#         filters: Integer, the dimensionality of the output space.\n",
    "#         kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "#             width and height of the 2D convolution window.\n",
    "#         t: Integer, expansion factor.\n",
    "#             t is always applied to the input size.\n",
    "#         alpha: Integer, width multiplier.\n",
    "#         s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "#             of the convolution along the width and height.Can be a single\n",
    "#             integer to specify the same value for all spatial dimensions.\n",
    "#         n: Integer, layer repeat times.\n",
    "\n",
    "#     # Returns\n",
    "#         Output tensor.\n",
    "#     \"\"\"\n",
    "\n",
    "#     x = _bottleneck(inputs, filters, kernel, t, alpha, strides)\n",
    "\n",
    "#     for i in range(1, n):\n",
    "#         x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def MobileNetv2(alpha=1.0):\n",
    "#     \"\"\"MobileNetv2\n",
    "#     This function defines a MobileNetv2 architectures.\n",
    "\n",
    "#     # Arguments\n",
    "#         input_shape: An integer or tuple/list of 3 integers, shape\n",
    "#             of input tensor.\n",
    "#         k: Integer, number of classes.\n",
    "#         alpha: Integer, width multiplier, better in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4].\n",
    "\n",
    "#     # Returns\n",
    "#         MobileNetv2 model.\n",
    "#     \"\"\"\n",
    "#     inputs = Input(shape=(1920,1080,3))\n",
    "\n",
    "#     first_filters = _make_divisible(32 * alpha, 8)\n",
    "#     x = _conv_block(inputs, first_filters, (3, 3), strides=(2, 2))\n",
    "\n",
    "#     x = _inverted_residual_block(x, 16, (3, 3), t=1, alpha=alpha, strides=1, n=1)\n",
    "#     x = _inverted_residual_block(x, 24, (3, 3), t=6, alpha=alpha, strides=2, n=2)\n",
    "#     x = _inverted_residual_block(x, 32, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "#     x = _inverted_residual_block(x, 64, (3, 3), t=6, alpha=alpha, strides=2, n=4)\n",
    "#     x = _inverted_residual_block(x, 96, (3, 3), t=6, alpha=alpha, strides=1, n=3)\n",
    "# #     x = _inverted_residual_block(x, 160, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "# #     x = _inverted_residual_block(x, 320, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "\n",
    "#     model = Model(inputs, x)\n",
    "#     # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\n",
    "#     print(model.summary())\n",
    "\n",
    "#     return model\n",
    "\n",
    "# x = MobileNetv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a9d02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"MobileNet v2 models for Keras.\n",
    "# Reference\n",
    "- [Inverted Residuals and Linear Bottlenecks Mobile Networks for\n",
    "   Classification, Detection and Segmentation]\n",
    "   (https://arxiv.org/abs/1801.04381)\n",
    "\"\"\"\n",
    " \n",
    " \n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from    tensorflow.keras import layers, models, Sequential, backend\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, ZeroPadding2D, AveragePooling2D, DepthwiseConv2D, Reshape\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.models import Model\n",
    "# from keras import backend as K\n",
    " \n",
    " \n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    " \n",
    " \n",
    "def relu6(x):\n",
    "    \"\"\"Relu 6\n",
    "    \"\"\"\n",
    "    return K.relu(x, max_value=6.0)\n",
    " \n",
    " \n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    \"\"\"Convolution Block\n",
    "    This function defines a 2D convolution operation with BN and relu6.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    " \n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    " \n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    return Activation(relu6)(x)\n",
    " \n",
    " \n",
    "def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "    \"\"\"Bottleneck\n",
    "    This function defines a basic bottleneck structure.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        alpha: Integer, width multiplier.\n",
    "        r: Boolean, Whether to use the residuals.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    " \n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    # Width\n",
    "    cchannel = int(filters * alpha)\n",
    " \n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    " \n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation(relu6)(x)\n",
    " \n",
    "    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    " \n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    "def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "    \"\"\"Inverted Residual Block\n",
    "    This function defines a sequence of 1 or more identical layers.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        alpha: Integer, width multiplier.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        n: Integer, layer repeat times.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    " \n",
    "    x = _bottleneck(inputs, filters, kernel, t, alpha, strides)\n",
    " \n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    "def MobileNetv2():\n",
    "    \"\"\"MobileNetv2\n",
    "    This function defines a MobileNetv2 architectures.\n",
    "    # Arguments\n",
    "        input_shape: An integer or tuple/list of 3 integers, shape\n",
    "            of input tensor.\n",
    "        k: Integer, number of classes.\n",
    "        alpha: Integer, width multiplier, better in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4].\n",
    "    # Returns\n",
    "        MobileNetv2 model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(540, 960, 3))\n",
    "    alpha = 1.0\n",
    "    first_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = _conv_block(inputs, first_filters, (3, 3), strides=(2, 2))\n",
    " \n",
    "    x = _inverted_residual_block(x, 16, (3, 3), t=1, alpha=1.0, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 24, (3, 3), t=6, alpha=1.0, strides=2, n=2)\n",
    "    x = _inverted_residual_block(x, 32, (3, 3), t=6, alpha=1.0, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 64, (3, 3), t=6, alpha=1.0, strides=1, n=4)\n",
    "    x = _inverted_residual_block(x, 96, (3, 3), t=6, alpha=1.0, strides=1, n=3)\n",
    "#     x = _inverted_residual_block(x, 160, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "#     x = _inverted_residual_block(x, 320, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    " \n",
    "    model = Model(inputs, x)\n",
    "#     model.summary()\n",
    "    return model\n",
    " \n",
    " \n",
    "# model = MobileNetv2((960,540, 3), 1.0)\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a11e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 540, 960, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 270, 480, 32) 896         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 270, 480, 32) 128         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 270, 480, 32) 0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 270, 480, 32) 1056        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 270, 480, 32) 128         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 270, 480, 32) 0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_80 (DepthwiseC (None, 270, 480, 32) 320         activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 270, 480, 32) 128         depthwise_conv2d_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 270, 480, 32) 0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 270, 480, 16) 528         activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 270, 480, 16) 64          conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 270, 480, 96) 1632        batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 270, 480, 96) 384         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 270, 480, 96) 0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_81 (DepthwiseC (None, 135, 240, 96) 960         activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 135, 240, 96) 384         depthwise_conv2d_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 135, 240, 96) 0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 135, 240, 24) 2328        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 135, 240, 24) 96          conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 135, 240, 144 3600        batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 135, 240, 144 576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 135, 240, 144 0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_82 (DepthwiseC (None, 135, 240, 144 1440        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 135, 240, 144 576         depthwise_conv2d_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 135, 240, 144 0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 135, 240, 24) 3480        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 135, 240, 24) 96          conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 135, 240, 24) 0           batch_normalization_260[0][0]    \n",
      "                                                                 batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 135, 240, 144 3600        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 135, 240, 144 576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 135, 240, 144 0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_83 (DepthwiseC (None, 68, 120, 144) 1440        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 68, 120, 144) 576         depthwise_conv2d_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 68, 120, 144) 0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 68, 120, 32)  4640        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 68, 120, 32)  128         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 68, 120, 192) 6336        batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 68, 120, 192) 768         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 68, 120, 192) 0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_84 (DepthwiseC (None, 68, 120, 192) 1920        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 68, 120, 192) 0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 68, 120, 32)  6176        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 68, 120, 32)  128         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 68, 120, 32)  0           batch_normalization_266[0][0]    \n",
      "                                                                 batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 68, 120, 192) 6336        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 68, 120, 192) 768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 68, 120, 192) 0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_85 (DepthwiseC (None, 68, 120, 192) 1920        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 68, 120, 192) 0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 68, 120, 32)  6176        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 68, 120, 32)  128         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 68, 120, 32)  0           batch_normalization_269[0][0]    \n",
      "                                                                 add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 68, 120, 192) 6336        add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 68, 120, 192) 768         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 68, 120, 192) 0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_86 (DepthwiseC (None, 68, 120, 192) 1920        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 68, 120, 192) 0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 68, 120, 64)  12352       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 68, 120, 64)  256         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 68, 120, 384) 24960       batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 68, 120, 384) 1536        conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 68, 120, 384) 0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_87 (DepthwiseC (None, 68, 120, 384) 3840        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 68, 120, 384) 0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 68, 120, 64)  24640       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 68, 120, 64)  256         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 68, 120, 64)  0           batch_normalization_275[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 68, 120, 384) 24960       add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 68, 120, 384) 1536        conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 68, 120, 384) 0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_88 (DepthwiseC (None, 68, 120, 384) 3840        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_88[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 68, 120, 384) 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 68, 120, 64)  24640       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 68, 120, 64)  256         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 68, 120, 64)  0           batch_normalization_278[0][0]    \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 68, 120, 384) 24960       add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 68, 120, 384) 1536        conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 68, 120, 384) 0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_89 (DepthwiseC (None, 68, 120, 384) 3840        activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_89[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 68, 120, 384) 0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 68, 120, 64)  24640       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 68, 120, 64)  256         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 68, 120, 64)  0           batch_normalization_281[0][0]    \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 68, 120, 384) 24960       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 68, 120, 384) 1536        conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 68, 120, 384) 0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_90 (DepthwiseC (None, 68, 120, 384) 3840        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_90[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 68, 120, 384) 0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 68, 120, 96)  36960       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 68, 120, 96)  384         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 68, 120, 576) 55872       batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 68, 120, 576) 2304        conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 68, 120, 576) 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_91 (DepthwiseC (None, 68, 120, 576) 5760        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 68, 120, 576) 2304        depthwise_conv2d_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 68, 120, 576) 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 68, 120, 96)  55392       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 68, 120, 96)  384         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 68, 120, 96)  0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 68, 120, 576) 55872       add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 68, 120, 576) 2304        conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 68, 120, 576) 0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_92 (DepthwiseC (None, 68, 120, 576) 5760        activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 68, 120, 576) 2304        depthwise_conv2d_92[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 68, 120, 576) 0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 68, 120, 96)  55392       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 68, 120, 96)  384         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 68, 120, 96)  0           batch_normalization_290[0][0]    \n",
      "                                                                 add_52[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 567,904\n",
      "Trainable params: 551,712\n",
      "Non-trainable params: 16,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CSRnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 540, 960, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model_4 (Functional)         (None, 68, 120, 96)       567904    \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 68, 120, 96)       864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_291 (Bat (None, 68, 120, 96)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 68, 120, 192)      1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_292 (Bat (None, 68, 120, 192)      768       \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 68, 120, 192)      1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_293 (Bat (None, 68, 120, 192)      768       \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 68, 120, 192)      1920      \n",
      "_________________________________________________________________\n",
      "density_map (Conv2D)         (None, 68, 120, 1)        193       \n",
      "=================================================================\n",
      "Total params: 580,097\n",
      "Trainable params: 562,945\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 假設你已經有 img_input 作為輸入\n",
    "img_input = Input(shape=(540, 960, 3))\n",
    "# 使用MobileNetV2\n",
    "mobilenetv2 = MobileNetv2()(img_input) \n",
    "x = Conv2D(filters=96, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2,groups=96,activation='relu',use_bias=False)(mobilenetv2)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=96,activation='relu',use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu',use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, strides=(1, 1), padding=\"same\", dilation_rate=2, groups=192,activation='relu')(x)\n",
    "# 最後輸出density map\n",
    "density_map = Conv2D(filters=1, kernel_size=1, name='density_map')(x)\n",
    "# 建立模型\n",
    "model = Model(img_input, density_map,name = 'CSRnet')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11ea420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "\n",
    "def conv_block (x, filters, kernel=(1,1), stride=(1,1)):\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel, strides=stride, padding='same',use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.relu6)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def depthwise_res_block(x, filters, kernel, stride, t, resdiual=False):\n",
    "\n",
    "    input_tensor = x\n",
    "    exp_channels = x.shape[-1]*t  \n",
    "\n",
    "    x = conv_block(x, exp_channels, (1,1), (1,1))\n",
    "\n",
    "    x = tf.keras.layers.DepthwiseConv2D(kernel, padding='same', strides=stride,use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.relu6)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters, (1,1), padding='same', strides=(1,1),use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if resdiual:\n",
    "        x = tf.keras.layers.add([x, input_tensor])\n",
    "\n",
    "    return x\n",
    "\n",
    "def inverted_residual_layers(x, filters, stride, t, n):\n",
    "\n",
    "    x = depthwise_res_block(x, filters, (3,3), stride, t, False)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        x = depthwise_res_block(x, filters, (3,3), (1,1), t, True)\n",
    "    \n",
    "    return x\n",
    "def MovblieNetV2 ():\n",
    "\n",
    "    img_input = tf.keras.layers.Input(shape=(540, 960, 3))\n",
    "\n",
    "    x = conv_block(img_input, 32, (3,3), (2,2))\n",
    "\n",
    "    x = tf.keras.layers.DepthwiseConv2D((3,3), padding='same', strides=(1,1),use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.relu6)(x)\n",
    "    \n",
    "    x = Conv2D(16, (1,1), padding='same', use_bias=False, strides=(1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = inverted_residual_layers(x, 16, (1,1), 1, 1)\n",
    "    x = inverted_residual_layers(x, 24, (2,2), 6, 2)\n",
    "    x = inverted_residual_layers(x, 32, (2,2), 6, 3)\n",
    "    x = inverted_residual_layers(x, 64, (1,1), 6, 4)\n",
    "    x = inverted_residual_layers(x, 96, (1,1), 6, 3)\n",
    "#     x = inverted_residual_layers(x, 160, (2,2), 6, 3)\n",
    "#     x = inverted_residual_layers(x, 320, (1,1), 6, 1)\n",
    "    model = tf.keras.Model(img_input, x)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c79ef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 540, 960, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 270, 480, 32) 864         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_749 (BatchN (None, 270, 480, 32) 128         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 270, 480, 32) 0           batch_normalization_749[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_247 (Depthwise (None, 270, 480, 32) 288         activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_750 (BatchN (None, 270, 480, 32) 128         depthwise_conv2d_247[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 270, 480, 32) 0           batch_normalization_750[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 270, 480, 16) 512         activation_506[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_751 (BatchN (None, 270, 480, 16) 64          conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 270, 480, 96) 1536        batch_normalization_751[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_752 (BatchN (None, 270, 480, 96) 384         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 270, 480, 96) 0           batch_normalization_752[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_248 (Depthwise (None, 135, 240, 96) 864         activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_753 (BatchN (None, 135, 240, 96) 384         depthwise_conv2d_248[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 135, 240, 96) 0           batch_normalization_753[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 135, 240, 24) 2304        activation_508[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_754 (BatchN (None, 135, 240, 24) 96          conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 135, 240, 144 3456        batch_normalization_754[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchN (None, 135, 240, 144 576         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 135, 240, 144 0           batch_normalization_755[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_249 (Depthwise (None, 135, 240, 144 1296        activation_509[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 135, 240, 144 576         depthwise_conv2d_249[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 135, 240, 144 0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 135, 240, 24) 3456        activation_510[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 135, 240, 24) 96          conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 135, 240, 24) 0           batch_normalization_757[0][0]    \n",
      "                                                                 batch_normalization_754[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 135, 240, 144 3456        add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 135, 240, 144 576         conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 135, 240, 144 0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_250 (Depthwise (None, 68, 120, 144) 1296        activation_511[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 68, 120, 144) 576         depthwise_conv2d_250[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 68, 120, 144) 0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 68, 120, 32)  4608        activation_512[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 68, 120, 32)  128         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 68, 120, 192) 6144        batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 68, 120, 192) 768         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_513 (Activation)     (None, 68, 120, 192) 0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_251 (Depthwise (None, 68, 120, 192) 1728        activation_513[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_251[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_514 (Activation)     (None, 68, 120, 192) 0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 68, 120, 32)  6144        activation_514[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchN (None, 68, 120, 32)  128         conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 68, 120, 32)  0           batch_normalization_763[0][0]    \n",
      "                                                                 batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 68, 120, 192) 6144        add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchN (None, 68, 120, 192) 768         conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_515 (Activation)     (None, 68, 120, 192) 0           batch_normalization_764[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_252 (Depthwise (None, 68, 120, 192) 1728        activation_515[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_252[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_516 (Activation)     (None, 68, 120, 192) 0           batch_normalization_765[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 68, 120, 32)  6144        activation_516[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchN (None, 68, 120, 32)  128         conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 68, 120, 32)  0           batch_normalization_766[0][0]    \n",
      "                                                                 add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 68, 120, 192) 6144        add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchN (None, 68, 120, 192) 768         conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_517 (Activation)     (None, 68, 120, 192) 0           batch_normalization_767[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_253 (Depthwise (None, 68, 120, 192) 1728        activation_517[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchN (None, 68, 120, 192) 768         depthwise_conv2d_253[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_518 (Activation)     (None, 68, 120, 192) 0           batch_normalization_768[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 68, 120, 64)  12288       activation_518[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchN (None, 68, 120, 64)  256         conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 68, 120, 384) 24576       batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchN (None, 68, 120, 384) 1536        conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_519 (Activation)     (None, 68, 120, 384) 0           batch_normalization_770[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_254 (Depthwise (None, 68, 120, 384) 3456        activation_519[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_254[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_520 (Activation)     (None, 68, 120, 384) 0           batch_normalization_771[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 68, 120, 64)  24576       activation_520[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchN (None, 68, 120, 64)  256         conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 68, 120, 64)  0           batch_normalization_772[0][0]    \n",
      "                                                                 batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 68, 120, 384) 24576       add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchN (None, 68, 120, 384) 1536        conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_521 (Activation)     (None, 68, 120, 384) 0           batch_normalization_773[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_255 (Depthwise (None, 68, 120, 384) 3456        activation_521[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_255[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_522 (Activation)     (None, 68, 120, 384) 0           batch_normalization_774[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 68, 120, 64)  24576       activation_522[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchN (None, 68, 120, 64)  256         conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 68, 120, 64)  0           batch_normalization_775[0][0]    \n",
      "                                                                 add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 68, 120, 384) 24576       add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchN (None, 68, 120, 384) 1536        conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_523 (Activation)     (None, 68, 120, 384) 0           batch_normalization_776[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_256 (Depthwise (None, 68, 120, 384) 3456        activation_523[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_777 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_256[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_524 (Activation)     (None, 68, 120, 384) 0           batch_normalization_777[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 68, 120, 64)  24576       activation_524[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_778 (BatchN (None, 68, 120, 64)  256         conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 68, 120, 64)  0           batch_normalization_778[0][0]    \n",
      "                                                                 add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 68, 120, 384) 24576       add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_779 (BatchN (None, 68, 120, 384) 1536        conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_525 (Activation)     (None, 68, 120, 384) 0           batch_normalization_779[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_257 (Depthwise (None, 68, 120, 384) 3456        activation_525[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_780 (BatchN (None, 68, 120, 384) 1536        depthwise_conv2d_257[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_526 (Activation)     (None, 68, 120, 384) 0           batch_normalization_780[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 68, 120, 96)  36864       activation_526[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_781 (BatchN (None, 68, 120, 96)  384         conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 68, 120, 576) 55296       batch_normalization_781[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_782 (BatchN (None, 68, 120, 576) 2304        conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_527 (Activation)     (None, 68, 120, 576) 0           batch_normalization_782[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_258 (Depthwise (None, 68, 120, 576) 5184        activation_527[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_783 (BatchN (None, 68, 120, 576) 2304        depthwise_conv2d_258[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_528 (Activation)     (None, 68, 120, 576) 0           batch_normalization_783[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 68, 120, 96)  55296       activation_528[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_784 (BatchN (None, 68, 120, 96)  384         conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 68, 120, 96)  0           batch_normalization_784[0][0]    \n",
      "                                                                 batch_normalization_781[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 68, 120, 576) 55296       add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_785 (BatchN (None, 68, 120, 576) 2304        conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_529 (Activation)     (None, 68, 120, 576) 0           batch_normalization_785[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_259 (Depthwise (None, 68, 120, 576) 5184        activation_529[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_786 (BatchN (None, 68, 120, 576) 2304        depthwise_conv2d_259[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_530 (Activation)     (None, 68, 120, 576) 0           batch_normalization_786[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 68, 120, 96)  55296       activation_530[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_787 (BatchN (None, 68, 120, 96)  384         conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 68, 120, 96)  0           batch_normalization_787[0][0]    \n",
      "                                                                 add_146[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 558,656\n",
      "Trainable params: 542,528\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MovblieNetV2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60185380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 540, 960, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 270, 480, 32) 864         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 270, 480, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 270, 480, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 270, 480, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 270, 480, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 270, 480, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 270, 480, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 270, 480, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 270, 480, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 270, 480, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 270, 480, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 271, 481, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 135, 240, 96) 864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 135, 240, 96) 384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 135, 240, 96) 0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 135, 240, 24) 2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 135, 240, 24) 96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 135, 240, 144 3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 135, 240, 144 576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 135, 240, 144 0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 135, 240, 144 1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 135, 240, 144 576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 135, 240, 144 0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 135, 240, 24) 3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 135, 240, 24) 96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 135, 240, 24) 0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 135, 240, 144 3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 135, 240, 144 576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 135, 240, 144 0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 137, 241, 144 0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 68, 120, 144) 1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 68, 120, 144) 576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 68, 120, 144) 0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 68, 120, 32)  4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 68, 120, 32)  128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 68, 120, 192) 6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 68, 120, 192) 768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 68, 120, 192) 0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 68, 120, 192) 1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 68, 120, 192) 768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 68, 120, 192) 0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 68, 120, 32)  6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 68, 120, 32)  128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 68, 120, 32)  0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 68, 120, 192) 6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 68, 120, 192) 768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 68, 120, 192) 0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 68, 120, 192) 1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 68, 120, 192) 768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 68, 120, 192) 0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 68, 120, 32)  6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 68, 120, 32)  128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 68, 120, 32)  0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 68, 120, 192) 6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 68, 120, 192) 768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 68, 120, 192) 0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 69, 121, 192) 0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 34, 60, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 34, 60, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 34, 60, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 34, 60, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 34, 60, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 34, 60, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 34, 60, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 34, 60, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 34, 60, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 34, 60, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 34, 60, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 34, 60, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 34, 60, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 34, 60, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 34, 60, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 34, 60, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 34, 60, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 34, 60, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 34, 60, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 34, 60, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 34, 60, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 34, 60, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 34, 60, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 34, 60, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 34, 60, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 34, 60, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 34, 60, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 34, 60, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 34, 60, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 34, 60, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 34, 60, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 34, 60, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 34, 60, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 34, 60, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 34, 60, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 34, 60, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 34, 60, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 34, 60, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 34, 60, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 34, 60, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 34, 60, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 34, 60, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 34, 60, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 34, 60, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 34, 60, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 34, 60, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 34, 60, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 34, 60, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 34, 60, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 34, 60, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 34, 60, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 34, 60, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 34, 60, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 34, 60, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 34, 60, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 34, 60, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 34, 60, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 34, 60, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 558,656\n",
      "Trainable params: 542,528\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "def MovblieNetV():\n",
    "    img_input = Input(shape=(540, 960, 3))\n",
    "\n",
    "    mobilenetv2 = MobileNetV2(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    # mobilenetv2 = MobileNetV2(include_top=False, input_tensor=img_input)\n",
    "    # x = mobilenetv2.layers[115].output\n",
    "    x = mobilenetv2.get_layer('block_12_add').output\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model\n",
    "\n",
    "m = MovblieNetV()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a8c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
